{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json\n",
    "import cv2\n",
    "import os,glob\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('/home/shuonan.chen/scratch_shuonan/code/pons_merfish_pipeline/processing/func')\n",
    "from registerCCF_util import *\n",
    "from prepare_img_utils import *\n",
    "from utils import get_paths\n",
    "\n",
    "def get_record(s):\n",
    "    return {\n",
    "        'filename':s.get('filename'),\n",
    "        'height': s.get('height'),\n",
    "        'width': s.get('width'), \n",
    "        'ox': s.get('anchoring')[0], \n",
    "        'oy': s.get('anchoring')[1],\n",
    "        'oz': s.get('anchoring')[2],\n",
    "        'ux': s.get('anchoring')[3],\n",
    "        'uy': s.get('anchoring')[4],\n",
    "        'uz': s.get('anchoring')[5], \n",
    "        'vx': s.get('anchoring')[6], \n",
    "        'vy': s.get('anchoring')[7],\n",
    "        'vz': s.get('anchoring')[8],\n",
    "    }\n",
    "\n",
    "HOMEDIR = '/allen/aind/scratch/shuonan.chen/code/pons_merfish_pipeline/'\n",
    "paths = get_paths()\n",
    "print(paths.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor=1/32;\n",
    "all_file_path = '/allen/aind/scratch/shuonan.chen/code/pons_merfish_pipeline/processing/image_xml/*.jpg'\n",
    "for f in glob.glob(all_file_path):\n",
    "    print(os.path.basename(f).split('cell_img_')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "slicename_all = [os.path.basename(f).split('cell_img_')[1].split('.')[0] for f in glob.glob(all_file_path)]\n",
    "slicename_all.sort()\n",
    "print(slicename_all, len(slicename_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b540c",
   "metadata": {},
   "source": [
    "# batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_flag = True\n",
    "plotting_2d = False\n",
    "plotting_3d = False\n",
    "slicenum = ['1']\n",
    "slicenum=[int(i) for i in slicenum]\n",
    "\n",
    "for name_of_slice in slicename_all:\n",
    "    image_files=glob.glob(HOMEDIR + f'/processing/image_xml/*{name_of_slice}.jpg')\n",
    "    # load your file\n",
    "    flat_name=[]  \n",
    "    for i in image_files:\n",
    "        result=re.search('(.*).jpg', i)\n",
    "        n=result.group(1)+('_nl.flat')\n",
    "        flat_name+=[n]\n",
    "    assert(len(image_files)==1)\n",
    "    im = cv2.imread(image_files[0])\n",
    "    h,w=im.shape[:2]\n",
    "    json_name=image_files \n",
    "    d = {'slicenum': slicenum, 'json_name': json_name,'flat_name':flat_name}\n",
    "    name_df=pd.DataFrame(data=d)\n",
    "    neurons=pd.read_csv(HOMEDIR+f'/processing/filt_neurons_all/filt_neurons_{name_of_slice}.csv')\n",
    "    neurons=neurons[neurons['slice'].isin(slicenum)]\n",
    "    Max=neurons['x'].max()\n",
    "    Min=neurons['y'].max()\n",
    "    neurons['rescale_x']=neurons['x']*scaling_factor\n",
    "    neurons['rescale_y']=neurons['y']*scaling_factor\n",
    "    neurons['rescale_x'] = neurons['rescale_x'].astype(float)+500 # this was accounting for the padding that we created for the image\n",
    "    neurons['rescale_y'] = neurons['rescale_y'].astype(float)+500\n",
    "    \n",
    "    # load visualign results \n",
    "    with open(HOMEDIR+f'/processing/visualign_rez/{name_of_slice}.json') as f:\n",
    "        vafile=json.load(f)\n",
    "    details={s.get('filename'):s for s in vafile['slices']}\n",
    "    assert(name_of_slice in list(details.keys())[0])\n",
    "    \n",
    "    rez = neurons.groupby('slice', group_keys=False).apply(lambda g: get_adjusted_points(g.assign(slice=g.name), name_df,details)).reset_index(drop=True)\n",
    "    neurons[['adjusted_x', 'adjusted_y']]= rez\n",
    "    neurons_nl=neurons.copy()\n",
    "    neurons_nl['clustid'] =neurons_nl['clustid'].astype(str)\n",
    "    \n",
    "    # load quickniii results \n",
    "    f = open(HOMEDIR+f'/processing/quicknii_rez/quicknii_{name_of_slice}.json','r')\n",
    "    data=json.loads(f.read())\n",
    "    anchor=pd.DataFrame.from_records([get_record(s) for s in data['slices']])\n",
    "    f.close()\n",
    "\n",
    "    vox_dfs = []\n",
    "    for slice_num, df in neurons_nl.groupby('slice'):\n",
    "        quicknii_cord = get_quicknii_cord(slice_num, df,name_df,anchor,h,w) # Height and Width of image file\n",
    "        vox_cord = get_vox_cord(quicknii_cord)\n",
    "        vox_dfs += [vox_cord]    \n",
    "    vox_df = pd.concat(vox_dfs)\n",
    "    \n",
    "    if save_flag:\n",
    "        vox_df.to_csv(HOMEDIR+f'/processing/registered_foo/registered_{name_of_slice}.csv',index=False)\n",
    "    \n",
    "    # optional plotting!\n",
    "    if plotting_3d:\n",
    "        plot_df = vox_df.copy()\n",
    "        fig = px.scatter_3d(plot_df, x='y_CCF', y='z_CCF', z='x_CCF', color='clustid')\n",
    "        fig.update_traces(marker=dict(size=.5),selector=dict(mode='markers'))\n",
    "        fig.update_scenes(aspectmode='data')\n",
    "        fig.show()\n",
    "    elif plotting_2d:\n",
    "        fig = px.scatter(plot_df, x='z_CCF', y='y_CCF', color='clustid')\n",
    "        fig.update_traces(marker=dict(size=1),selector=dict(mode='markers'))\n",
    "        fig.update_yaxes(scaleanchor='x', scaleratio=1)\n",
    "        fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_name=[]  \n",
    "for i in image_files:\n",
    "    result=re.search('(.*).jpg', i)\n",
    "    n=result.group(1)+('_nl.flat')\n",
    "    flat_name+=[n]\n",
    "slicenum=[int(i) for i in slicenum]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(image_files[0])\n",
    "w=im.shape[1]\n",
    "h=im.shape[0]\n",
    "\n",
    "json_name=image_files \n",
    "d = {'slicenum': slicenum, 'json_name': json_name,'flat_name':flat_name}\n",
    "name_df=pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=pd.read_csv(HOMEDIR+f'/processing/filt_neurons_all/filt_neurons_{name_of_slice}.csv')\n",
    "neurons=neurons[neurons['slice'].isin(slicenum)]\n",
    "Max=neurons['x'].max()\n",
    "Min=neurons['y'].max()\n",
    "neurons['rescale_x']=(neurons['x']*scaling_factor)\n",
    "neurons['rescale_y']=(neurons['y']*scaling_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d19e2f",
   "metadata": {},
   "source": [
    "# invert warping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"visualign.json\") as f:\n",
    "    vafile=json.load(f)\n",
    "details={s.get('filename'):s for s in vafile['slices']}\n",
    "assert(name_of_slice in list(details.keys())[0])\n",
    "\n",
    "neurons[['adjusted_x', 'adjusted_y']] = neurons.groupby('slice').apply(get_adjusted_points).reset_index(drop=True)\n",
    "neurons_nl=neurons.copy()\n",
    "neurons_nl['clustid'] =neurons_nl['clustid'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648aaf54",
   "metadata": {},
   "source": [
    "# invert affine transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(s):\n",
    "    return {\n",
    "        'filename':s.get('filename'),\n",
    "        'height': s.get('height'),\n",
    "        'width': s.get('width'), \n",
    "        'ox': s.get('anchoring')[0], \n",
    "        'oy': s.get('anchoring')[1],\n",
    "        'oz': s.get('anchoring')[2],\n",
    "        'ux': s.get('anchoring')[3],\n",
    "        'uy': s.get('anchoring')[4],\n",
    "        'uz': s.get('anchoring')[5], \n",
    "        'vx': s.get('anchoring')[6], \n",
    "        'vy': s.get('anchoring')[7],\n",
    "        'vz': s.get('anchoring')[8],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17465d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('quicknii.json','r')\n",
    "data=json.loads(f.read())\n",
    "anchor=pd.DataFrame.from_records([get_record(s) for s in data['slices']])\n",
    "f.close()\n",
    "\n",
    "vox_dfs = []\n",
    "for slice_num, df in neurons_nl.groupby('slice'):\n",
    "    quicknii_cord = get_quicknii_cord(slice_num, df,h,w) # Height and Width of image file\n",
    "    vox_cord = get_vox_cord(quicknii_cord)\n",
    "    vox_dfs += [vox_cord]    \n",
    "vox_df = pd.concat(vox_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049374cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b78bb00",
   "metadata": {},
   "source": [
    "# plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_df = vox_df.copy()\n",
    "fig = px.scatter_3d(plot_df, x='y_CCF', y='z_CCF', z='x_CCF', color='clustid')\n",
    "fig.update_traces(marker=dict(size=.5),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.update_scenes(aspectmode='data')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8220b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allensdk",
   "language": "python",
   "name": "allensdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
